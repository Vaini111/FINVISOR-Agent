{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# AI Service Deployment Notebook\nThis notebook contains steps and code to test, promote, and deploy an Agent as an AI Service.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Contents\nThis notebook contains the following parts:\n\n1. Setup\n2. Initialize all the variables needed by the AI Service\n3. Define the AI service function\n4. Deploy an AI Service\n5. Test the deployed AI Service\n\n## 1. Set up the environment\n\nBefore you can run this notebook, you must perform the following setup tasks:"}, {"metadata": {}, "cell_type": "markdown", "source": "### Connection to WML\nThis cell defines the credentials required to work with watsonx API for both the execution in the project, \nas well as the deployment and runtime execution of the function.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nfrom ibm_watsonx_ai import APIClient, Credentials\nimport getpass\n\ncredentials = Credentials(\n    url=\"https://us-south.ml.cloud.ibm.com\",\n    api_key=getpass.getpass(\"Please enter your api key (hit enter): \")\n)\n\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Connecting to a space\nA space will be be used to host the promoted AI Service.\n"}, {"metadata": {}, "cell_type": "code", "source": "space_id = \"e79f71ea-a366-4dbb-8dd3-44c4037bb187\"\nclient.set.default_space(space_id)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Promote asset(s) to space\nWe will now promote assets we will need to stage in the space so that we can access their data from the AI service.\n"}, {"metadata": {}, "cell_type": "code", "source": "source_project_id = \"173c0a49-2252-4068-ae88-1821ae9a095d\"\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 2. Create the AI service function\nWe first need to define the AI service function\n\n### 2.1 Define the function"}, {"metadata": {}, "cell_type": "code", "source": "params = {\n    \"space_id\": space_id,\n}\n\ndef gen_ai_service(context, params = params, **custom):\n    # import dependencies\n    from langchain_ibm import ChatWatsonx\n    from ibm_watsonx_ai import APIClient\n    from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n    from langchain_core.messages import AIMessage, HumanMessage\n    from langgraph.checkpoint.memory import MemorySaver\n    from langgraph.prebuilt import create_react_agent\n    import json\n    import requests\n\n    model = \"ibm/granite-3-3-8b-instruct\"\n    \n    service_url = \"https://us-south.ml.cloud.ibm.com\"\n    # Get credentials token\n    credentials = {\n        \"url\": service_url,\n        \"token\": context.generate_token()\n    }\n\n    # Setup client\n    client = APIClient(credentials)\n    space_id = params.get(\"space_id\")\n    client.set.default_space(space_id)\n\n\n\n    def create_chat_model(watsonx_client):\n        parameters = {\n            \"frequency_penalty\": 0,\n            \"max_tokens\": 2000,\n            \"presence_penalty\": 0,\n            \"temperature\": 0,\n            \"top_p\": 1\n        }\n\n        chat_model = ChatWatsonx(\n            model_id=model,\n            url=service_url,\n            space_id=space_id,\n            params=parameters,\n            watsonx_client=watsonx_client,\n        )\n        return chat_model\n    \n    \n    def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n        from langchain_core.tools import StructuredTool\n        utility_agent_tool = Toolkit(\n            api_client=api_client\n        ).get_tool(tool_name)\n    \n        tool_description = utility_agent_tool.get(\"description\")\n    \n        if (kwargs.get(\"tool_description\")):\n            tool_description = kwargs.get(\"tool_description\")\n        elif (utility_agent_tool.get(\"agent_description\")):\n            tool_description = utility_agent_tool.get(\"agent_description\")\n        \n        tool_schema = utility_agent_tool.get(\"input_schema\")\n        if (tool_schema == None):\n            tool_schema = {\n                \"type\": \"object\",\n                \"additionalProperties\": False,\n                \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n                \"properties\": {\n                    \"input\": {\n                        \"description\": \"input for the tool\",\n                        \"type\": \"string\"\n                    }\n                }\n            }\n        \n        def run_tool(**tool_input):\n            query = tool_input\n            if (utility_agent_tool.get(\"input_schema\") == None):\n                query = tool_input.get(\"input\")\n    \n            results = utility_agent_tool.run(\n                input=query,\n                config=params\n            )\n            \n            return results.get(\"output\")\n        \n        return StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=run_tool,\n            args_schema=tool_schema\n        )\n    \n    \n    def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n        from langchain_core.tools import StructuredTool\n        import ast\n    \n        def call_tool(**kwargs):\n            tree = ast.parse(tool_code, mode=\"exec\")\n            custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n            function_name = custom_tool_functions[0].name\n            compiled_code = compile(tree, 'custom_tool', 'exec')\n            namespace = tool_params if tool_params else {}\n            exec(compiled_code, namespace)\n            return namespace[function_name](**kwargs)\n            \n        tool = StructuredTool(\n            name=tool_name,\n            description = tool_description,\n            func=call_tool,\n            args_schema=tool_schema\n        )\n        return tool\n    \n    def create_custom_tools():\n        custom_tools = []\n    \n\n    def create_tools(inner_client, context):\n        tools = []\n        \n        config = {\n            \"maxResults\": 10\n        }\n        tools.append(create_utility_agent_tool(\"GoogleSearch\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, inner_client))\n        config = {\n            \"maxResults\": 5\n        }\n        tools.append(create_utility_agent_tool(\"Wikipedia\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"WebCrawler\", config, inner_client))\n        config = {\n        }\n        tools.append(create_utility_agent_tool(\"Weather\", config, inner_client))\n        return tools\n    \n    def create_agent(model, tools, messages):\n        memory = MemorySaver()\n        instructions = \"\"\"# Notes\n- Use markdown syntax for formatting code snippets, links, JSON, tables, images, files.\n- Any HTML tags must be wrapped in block quotes, for example ```<html>```.\n- When returning code blocks, specify language.\n- Sometimes, things don't go as planned. Tools may not provide useful information on the first few tries. You should always try a few different approaches before declaring the problem unsolvable.\n- When the tool doesn't give you what you were asking for, you must either use another tool or a different tool input.\n- When using search engines, you try different formulations of the query, possibly even in a different language.\n- You cannot do complex calculations, computations, or data manipulations without using tools.\n- If you need to call a tool to compute something, always call it instead of saying you will call it.\n\nIf a tool returns an IMAGE in the result, you must include it in your answer as Markdown.\n\nExample:\n\nTool result: IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\nMarkdown to return to user: ![Generated image]({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n\nYou are a smart, friendly, and helpful AI assistant. Your role is to assist users by answering their questions clearly, politely, and respectfully. Always stay informative, supportive, and easy to understand, especially for beginners. Think step-by-step when tasks involve instructions, processes, or decision-making. Your responses should be short, simple, and beginner-friendly, avoiding technical jargon unless it's clearly explained in everyday language. Provide real-life examples whenever possible to help users relate. Use Markdown syntax to format code snippets, links, JSON, tables, images, or file references; and wrap any HTML tags in block quotes, such as <html>. When returning code blocks, always specify the language like json or python. For image outputs from tools, use the format: ![Generated image]({commonApiUrl}/path-to-image.png). If a tool doesn\u2019t give useful results on the first try, try a different approach, reformulate the query, or use another tool\u2014possibly even in a different language. You cannot perform complex calculations or data manipulations without using tools, so always call one instead of assuming or estimating. If you cannot directly answer a question, say something like \u201cBased on the information I have\u2026\u201d or guide the user to an official source. Never say \u201cI don\u2019t know\u201d bluntly. Do not collect, request, or store any personal or sensitive information such as Aadhaar numbers, passwords, OTPs, bank account details, or mobile numbers. If a user shares such details, gently inform them it\u2019s not needed and remind them to stay safe online. Warn users about phishing scams and fake links, and recommend reporting fraud at https://cybercrime.gov.in or contacting their bank. Always maintain a warm, supportive tone and be inclusive across languages. Support English and regional languages (like Hindi or Telugu) when requested, and tailor answers to suit the local or cultural context. Your goal is to educate the user, protect them from digital risks, and build their trust and confidence in using digital financial tools. \nYou are a helpful assistant that uses tools to answer questions in detail.\nWhen greeted, say \\\"Hi, I am FINVISOR.ai agent. How can I help you?\\\"\nYou are a helpful assistant that uses tools to answer questions in detail. When greeted, say \\\"Hi, I am FINVISOR. How can I help you?\\\" You are a helpful AI assistant trained to improve digital financial literacy for citizens, especially beginners, rural users, and the elderly. Your job is to: answer questions about UPI, net banking, loans, scams, budgeting, government financial schemes, the stock market, and personal finance management. Explain things simply, like a friendly teacher. Avoid technical jargon unless explained clearly. Never collect or ask for personal information like Aadhaar, PAN, OTP, or bank details. Safety first: always warn users about phishing, scams, and OTP misuse. Suggest reporting fraud to https://cybercrime.gov.in or contacting their bank immediately. Use trusted sources only, such as the RBI official website, NPCI (https://www.npci.org.in), and government financial portals like Jan Dhan, NSAP, etc. Provide multilingual support: be ready to assist in English and regional languages (e.g., Hindi, Telugu) if asked. Keep your tone respectful, friendly, and culturally sensitive and inclusive at all times. Your answer format should include short, clear sentences, bullet points or steps when needed, and a warm, non-robotic tone. Never say: \\\"I don't know.\\\" Instead, say: \\\"Based on available information...\\\" or guide the user to a trusted website for more details. Your responses should always prioritize the user's understanding and safety.  Examples of questions users might ask: \\\"How do I send money using UPI?\\\", \\\"What is a safe interest rate for a loan?\\\", or \\\"How do I report a scam call asking for OTP?\\\"\n \\\"What is a phishing scam?\\\",  \\\"How can I create a monthly budget?\\\", or \\\"What is Jan Dhan Yojana and who can apply?\\\" Your overall goal is to empower users with safe, accessible, and trustworthy financial knowledge that builds their confidence in using digital financial tools.\"\"\"\n        for message in messages:\n            if message[\"role\"] == \"system\":\n                instructions += message[\"content\"]\n        graph = create_react_agent(model, tools=tools, checkpointer=memory, state_modifier=instructions)\n        return graph\n    \n    def convert_messages(messages):\n        converted_messages = []\n        for message in messages:\n            if (message[\"role\"] == \"user\"):\n                converted_messages.append(HumanMessage(content=message[\"content\"]))\n            elif (message[\"role\"] == \"assistant\"):\n                converted_messages.append(AIMessage(content=message[\"content\"]))\n        return converted_messages\n\n    def generate(context):\n        payload = context.get_json()\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n        \n        generated_response = agent.invoke(\n            { \"messages\": convert_messages(messages) },\n            { \"configurable\": { \"thread_id\": \"42\" } }\n        )\n\n        last_message = generated_response[\"messages\"][-1]\n        generated_response = last_message.content\n\n        execute_response = {\n            \"headers\": {\n                \"Content-Type\": \"application/json\"\n            },\n            \"body\": {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"message\": {\n                       \"role\": \"assistant\",\n                       \"content\": generated_response\n                    }\n                }]\n            }\n        }\n\n        return execute_response\n\n    def generate_stream(context):\n        print(\"Generate stream\", flush=True)\n        payload = context.get_json()\n        headers = context.get_headers()\n        is_assistant = headers.get(\"X-Ai-Interface\") == \"assistant\"\n        messages = payload.get(\"messages\")\n        inner_credentials = {\n            \"url\": service_url,\n            \"token\": context.get_token()\n        }\n        inner_client = APIClient(inner_credentials)\n        model = create_chat_model(inner_client)\n        tools = create_tools(inner_client, context)\n        agent = create_agent(model, tools, messages)\n\n        response_stream = agent.stream(\n            { \"messages\": messages },\n            { \"configurable\": { \"thread_id\": \"42\" } },\n            stream_mode=[\"updates\", \"messages\"]\n        )\n\n        for chunk in response_stream:\n            chunk_type = chunk[0]\n            finish_reason = \"\"\n            usage = None\n            if (chunk_type == \"messages\"):\n                message_object = chunk[1][0]\n                if (message_object.type == \"AIMessageChunk\" and message_object.content != \"\"):\n                    message = {\n                        \"role\": \"assistant\",\n                        \"content\": message_object.content\n                    }\n                else:\n                    continue\n            elif (chunk_type == \"updates\"):\n                update = chunk[1]\n                if (\"agent\" in update):\n                    agent = update[\"agent\"]\n                    agent_result = agent[\"messages\"][0]\n                    if (agent_result.additional_kwargs):\n                        kwargs = agent[\"messages\"][0].additional_kwargs\n                        tool_call = kwargs[\"tool_calls\"][0]\n                        if (is_assistant):\n                            message = {\n                                \"role\": \"assistant\",\n                                \"step_details\": {\n                                    \"type\": \"tool_calls\",\n                                    \"tool_calls\": [\n                                        {\n                                            \"id\": tool_call[\"id\"],\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"args\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    ] \n                                }\n                            }\n                        else:\n                            message = {\n                                \"role\": \"assistant\",\n                                \"tool_calls\": [\n                                    {\n                                        \"id\": tool_call[\"id\"],\n                                        \"type\": \"function\",\n                                        \"function\": {\n                                            \"name\": tool_call[\"function\"][\"name\"],\n                                            \"arguments\": tool_call[\"function\"][\"arguments\"]\n                                        }\n                                    }\n                                ]\n                            }\n                    elif (agent_result.response_metadata):\n                        # Final update\n                        message = {\n                            \"role\": \"assistant\",\n                            \"content\": agent_result.content\n                        }\n                        finish_reason = agent_result.response_metadata[\"finish_reason\"]\n                        if (finish_reason): \n                            message[\"content\"] = \"\"\n\n                        usage = {\n                            \"completion_tokens\": agent_result.usage_metadata[\"output_tokens\"],\n                            \"prompt_tokens\": agent_result.usage_metadata[\"input_tokens\"],\n                            \"total_tokens\": agent_result.usage_metadata[\"total_tokens\"]\n                        }\n                elif (\"tools\" in update):\n                    tools = update[\"tools\"]\n                    tool_result = tools[\"messages\"][0]\n                    if (is_assistant):\n                        message = {\n                            \"role\": \"assistant\",\n                            \"step_details\": {\n                                \"type\": \"tool_response\",\n                                \"id\": tool_result.id,\n                                \"tool_call_id\": tool_result.tool_call_id,\n                                \"name\": tool_result.name,\n                                \"content\": tool_result.content\n                            }\n                        }\n                    else:\n                        message = {\n                            \"role\": \"tool\",\n                            \"id\": tool_result.id,\n                            \"tool_call_id\": tool_result.tool_call_id,\n                            \"name\": tool_result.name,\n                            \"content\": tool_result.content\n                        }\n                else:\n                    continue\n\n            chunk_response = {\n                \"choices\": [{\n                    \"index\": 0,\n                    \"delta\": message\n                }]\n            }\n            if (finish_reason):\n                chunk_response[\"choices\"][0][\"finish_reason\"] = finish_reason\n            if (usage):\n                chunk_response[\"usage\"] = usage\n            yield chunk_response\n\n    return generate, generate_stream\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 2.2 Test locally"}, {"metadata": {}, "cell_type": "code", "source": "# Initialize AI Service function locally\nfrom ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\nstreaming = False\nfindex = 1 if streaming else 0\nlocal_function = gen_ai_service(context,  space_id=space_id)[findex]\nmessages = []", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "local_question = \"Change this question to test your function\"\n\nmessages.append({ \"role\" : \"user\", \"content\": local_question })\n\ncontext = RuntimeContext(api_client=client, request_payload_json={\"messages\": messages})\n\nresponse = local_function(context)\n\nresult = ''\n\nif (streaming):\n    for chunk in response:\n        print(chunk, end=\"\\n\\n\", flush=True)\nelse:\n    print(response)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 3. Store and deploy the AI Service\nBefore you can deploy the AI Service, you must store the AI service in your watsonx.ai repository."}, {"metadata": {}, "cell_type": "code", "source": "# Look up software specification for the AI service\nsoftware_spec_id_in_project = \"45f12dfe-aa78-5b8d-9f38-0ee223c47309\"\nsoftware_spec_id = \"\"\n\ntry:\n    software_spec_id = client.software_specifications.get_id_by_name(\"runtime-24.1-py3.11\")\nexcept:\n    software_spec_id = client.spaces.promote(software_spec_id_in_project, source_project_id, space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Define the request and response schemas for the AI service\nrequest_schema = {\n    \"application/json\": {\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"messages\": {\n                \"title\": \"The messages for this chat session.\",\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"role\": {\n                            \"title\": \"The role of the message author.\",\n                            \"type\": \"string\",\n                            \"enum\": [\"user\",\"assistant\"]\n                        },\n                        \"content\": {\n                            \"title\": \"The contents of the message.\",\n                            \"type\": \"string\"\n                        }\n                    },\n                    \"required\": [\"role\",\"content\"]\n                }\n            }\n        },\n        \"required\": [\"messages\"]\n    }\n}\n\nresponse_schema = {\n    \"application/json\": {\n        \"oneOf\": [{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service_stream\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices.\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"title\":\"The index of this result.\"},\"delta\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"content\":{\"description\":\"The contents of the message.\",\"type\":\"string\"},\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]},{\"$schema\":\"http://json-schema.org/draft-07/schema#\",\"type\":\"object\",\"description\":\"AI Service response for /ai_service\",\"properties\":{\"choices\":{\"description\":\"A list of chat completion choices\",\"type\":\"array\",\"items\":{\"type\":\"object\",\"properties\":{\"index\":{\"type\":\"integer\",\"description\":\"The index of this result.\"},\"message\":{\"description\":\"A message result.\",\"type\":\"object\",\"properties\":{\"role\":{\"description\":\"The role of the author of this message.\",\"type\":\"string\"},\"content\":{\"title\":\"Message content.\",\"type\":\"string\"}},\"required\":[\"role\"]}}}}},\"required\":[\"choices\"]}]\n    }\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Store the AI service in the repository\nai_service_metadata = {\n    client.repository.AIServiceMetaNames.NAME: \"FINVISOR\",\n    client.repository.AIServiceMetaNames.DESCRIPTION: \"\",\n    client.repository.AIServiceMetaNames.SOFTWARE_SPEC_ID: software_spec_id,\n    client.repository.AIServiceMetaNames.CUSTOM: {},\n    client.repository.AIServiceMetaNames.REQUEST_DOCUMENTATION: request_schema,\n    client.repository.AIServiceMetaNames.RESPONSE_DOCUMENTATION: response_schema,\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nai_service_details = client.repository.store_ai_service(meta_props=ai_service_metadata, ai_service=gen_ai_service)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Get the AI Service ID\n\nai_service_id = client.repository.get_ai_service_id(ai_service_details)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Deploy the stored AI Service\ndeployment_custom = {\n    \"avatar_icon\": \"Bot\",\n    \"avatar_color\": \"background\",\n    \"placeholder_image\": \"default\",\n    \"sample_questions\": [\"How do I budget my monthly expenses?\",\"What is the 50-30-20 budgeting rule?\",\"What are common online banking scams?\",\"Is taking a gold loan safe?\"]\n}\ndeployment_metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: \"FINVISOR\",\n    client.deployments.ConfigurationMetaNames.ONLINE: {},\n    client.deployments.ConfigurationMetaNames.CUSTOM: deployment_custom,\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Aims to develop intelligent virtual assistant that enhances financial awareness and digital safety.\",\n    client.repository.AIServiceMetaNames.TAGS: [\"wx-agent\"]\n}\n\nfunction_deployment_details = client.deployments.create(ai_service_id, meta_props=deployment_metadata, space_id=space_id)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 4. Test AI Service"}, {"metadata": {}, "cell_type": "code", "source": "# Get the ID of the AI Service deployment just created\n\ndeployment_id = client.deployments.get_id(function_deployment_details)\nprint(deployment_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "messages = []\nremote_question = \"Change this question to test your function\"\nmessages.append({ \"role\" : \"user\", \"content\": remote_question })\npayload = { \"messages\": messages }", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "result = client.deployments.run_ai_service(deployment_id, payload)\nif \"error\" in result:\n    print(result[\"error\"])\nelse:\n    print(result)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully deployed and tested the AI Service! You can now view\nyour deployment and test it as a REST API endpoint.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}